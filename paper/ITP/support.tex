\section{Reasoning support}
\label{sec:reasoning-support}
We now turn to the second part of the \Equations package: the derivation
of support definitions to help reasoning on the generated implementations.

\subsection{Building equations}

The easiest step is constructing the proofs of the equations as
propositional equalities.

\begin{definition}[Equations statements]
  We recurse on the splitting tree, 
  bookkeeping the current label $\ell$, initially $ε$,
  and for each $\Compute{Δ \vdash \vec{p} : Γ}{rhs}$
  node we inspect the right-hand side and generate a statement:
  \begin{itemize}
  \item $\Prog{t}$: the equation is simply $Π~Δ, \cst{f.\ell}~\vec{p}~=t$.
  % \item $\Empty{t}$: we make an instance of the following typeclass:
  %   \vspace{0.1em}
  %   \input{imposs.coq}

  %   In this case we generate an instance of $Π~Δ, \ind{ImpossibleCall} (\cst{f.\ell}~\vec{p})$.
    
  \item $\Refine{t}{Δ' \vdash \vec{\var{v}}^x, \var{x}, \vec{\var{v}}_x :
      Δ^x, \var{x} : τ, Δ_x}{\ell'}{s}$: 
    We know that the new programming problem is just a reordering of the
    variables in $Δ$ after having inserted a declaration for the refined 
    object and abstracted the remaining $Δ_x$ context. 
    The auxiliary definition $\helper{f}{\ell'}$ produces an object refining 
    this context, we can hence generate an indirection equation for the
    helper function: 
    $Π~Δ, \cst{f.\ell}~\vec{p} = \helper{f}{\ell'}~\vec{\var{v}}^x~t~\vec{\var{v}}_x$.
    We continue the generation of equations, considering the new
    programming problem and setting the current label to $\ell'$.
  \end{itemize}
\end{definition}

All of these goals are solvable by simply unfolding the definition 
of the function and simplifying the goal: the constructor forms in the
leaf patterns direct the reduction. If we didn't use any axioms during
the definition, then these follow definitionally. When we encounter
axioms in these proofs we simply rewrite using their expected
computational behavior.

We create a database of rewrite rules named $\cst{f}$ with the proofs 
of these equations, to allow simplification by rewriting, abstracting
many steps of reasoning and computation in a single rewrite.

\subsection{Induction principle}

The next step is to build the inductive graph of the function.
Considering $\cst{f} : Π~Γ,~\fcomp{f}~\bar{Γ}$, we want 
to build an inductive relation $\find{f} : Π~Γ,~\fcomp{f}~\bar{Γ} "->" \Prop$ that relates 
arguments $\bar{Γ}$ to results $\fcomp{f}~\bar{Γ}$.

We first define a function that finds the occurrences of recursive calls
in a right-hand side term and abstracts them by variables. This is easy
to do given that all the recursive calls are labeled by the trivial 
\fcompproj{f} projection. 
\begin{definition}[Abstracting recursive calls]
  The \absrec{f}{t} operator is defined by recursion on the term $t$, 
  under a local context $Δ$, initially empty.
  The operator builds a context representing the abstracted
  recursive calls and a new term using these abstracted calls.
  By case on $t$:
  \begin{itemize}
  \item $\fcompproj{f}~\vec{t}~p$ :
    We recursively compute the abstractions in \vec{t} giving us 
    a new context $Δ'$ and terms $\vec{t'}$.
    We extend $Δ'$ with a fresh declaration 
    $\var{res} := λ~Δ,~\cst{f}~\vec{t'} : Π~Δ,~\fcomp{f}~\vec{t'}$ and 
    the term becomes $\var{res}~\bar{Δ}$.

  \item $λ \var{x} : τ, b$ :
    Let the result of abstracting $b$ in an extended context 
    $Δ, \var{x} : τ$ be $(Δ', b')$, we return $(Δ', λ \var{x} : τ, b')$.

  \item $f~e$ :
    We simply combine the results of abstracting $f$ and $e$ separately.
    
  \item $\coqdockw{let}~\var{x} \coloneqq t~\coqdockw{in}~b$ :
    We do the abstractions in $t$ resulting in $Δ', t'$ 
    and recursively call the abstraction on $b$ in a context 
    extended with $(\var{x}~\coloneqq~t')$. We simply combine the 
    resulting contexts and terms.

  \item Otherwise we return the empty context and the term unchanged.
  \end{itemize}
\end{definition}

Once we get the recursive calls abstracted, we will need to add
induction hypotheses to the context.

\begin{definition}[Induction hypotheses generation]
  Given a context $Δ$ of results produced by the \absrec{f}{t} operator,
  we define the induction hypotheses context by a simple map on $Δ$,
  denoted $\IndHyps{Δ}$.
  For each binding $\var{res} : Π~Δ,~\fcomp{f}~\vec{t}$ we build a
  new binding $\var{resind} : Π~Δ,~\find{f}~\vec{t}~(\var{res}~\bar{Δ})$.
\end{definition}

We are now ready to build the inductive graph.

\begin{definition}[Inductive graph]
  We compute the constructors of the $\find{f}$ relation by recursion on the
  splitting tree:
  
  \begin{itemize}
  \item $\Split{c}{x}{s}$ :
    Again splitting nodes are basically ignored, we just
    collect the constructor statements for the splittings $s$, if any.

  \item $\Rec{v}{s}$ :
    Recursion nodes are also ignored when we compute the inductive
    graph, after all they just produce different ways to build
    $\fcomp{f}$ objects. We just recurse on the splitting $s$.

  \item $\Compute{c}{rhs}$ :
    By case on $rhs$:

    \begin{itemize}
    \item $\Prog{t}$ :
      We abstract the recursive calls of the term using the function
      \absrec{f}{t} which returns a context $ψ$ and a new term
      $t'$. We return the statement
      \[Π~Δ~Ψ~\IndHyps{Ψ},~\find{f}~\vec{p}~t'\]
      
    % \item $\Empty{t}$ : this case is impossible hence no constructor is
    %   needed.
    \item $\Refine{t}{Δ' \vdash \vec{\var{v}}^x, \var{x}, \vec{\var{v}}_x :
        Δ^x, \var{x} : τ, Δ_x}{\helper{f}{\ell}}{s}$ :
      As for the equation, we just have to do an indirection to the 
      inductive graph of the auxiliary function, but we have to take
      into account the recursive calls of the refined term too.
      We compute $\absrec{f}{t} = (ψ, t')$ and return:
      \[\begin{array}{l}
        Π~Δ^x~Δ_x~Ψ~\IndHyps{Ψ}~(\var{res} :
        {\fcomp{\helper{f}{\ell}}}~\bar{Δ^x}~\bar{Δ_x}) \\
        \find{\helper{f}{\ell}}~\vec{\var{v}}^x~t'~\vec{\var{v}}_x~\var{res} "->"
        \find{f}~\vec{p}~\var{res}
      \end{array}\]
      \vspace{-0.7em}
      
      We continue with the generation of the \find{\helper{f}{\ell}} graph.
    \end{itemize}  
  \end{itemize}
\end{definition}

The result of the inductive graph construction is hence a mutual
inductive type $\vec{\find{f.\ell} : Π~Δ,~\fcomp{f}~\vec{t}}$
with one inductive definition per refinement node and one
for the toplevel definition.
We can now prove that the function (and its helpers) corresponds to this 
graph by proving the following lemma:

\begin{theorem}[Graph lemma]
  We prove $Π~Δ,~\find{f}~\bar{Δ}~(\cst{f}~\bar{Δ})$ by following the 
  splitting tree.
  \begin{itemize}
  \item $\Rec{c}{s}$ :
    We replay recursion nodes, giving us new ways to prove $\find{f}$
    that we will use to prove the goals corresponding to induction
    hypotheses.

  \item $\Split{c}{x}{s}$ :
    Each split is simply replayed, empty ones solve the goal directly.

  \item $\Compute{Δ \vdash \vec{p} : Γ}{rhs}$ :
    At computation nodes our goal will necessarily be simplifiable 
    by an equation because we replayed the whole splitting, i.e. it 
    will have the form $Π~Δ,~\find{f}~\vec{p}~(\cst{f}~\vec{p})$.
    By case on $rhs$:

    \begin{itemize}
    \item $\Prog{t}$ :
      We rewrite with the equation for this node and apply one 
      of the constructors for the graph. We will optionally get 
      subgoals for induction hypotheses here if $t$ had recursive
      calls in it. They are solved by a proof search, in exactly the
      same way as the proofs for the recursive calls were found.
      
    % \item $\Empty{t}$ : this case has no constructor, we can call
    %   \text{\cst{impossible\_call}} with the application
    %   $\cst{f}~\vec{p}$ to discharge this goal.

    \item $\Refine{t}{\prob{Δ'}{\vec{\var{v}}}{Γ'}}{\ell}{s}$ :
      Here we can rewrite with the indirection equation and 
      apply the indirection constructor for the inductive
      graph, then solve potential induction subgoals. 
      We will be left with a subgoal for the \find{\helper{f}{\ell}} graph mentioning
      the refined term $t$. We must simply abstract this term by 
      a fresh variable to obtain a goal of the form 
      
      $Π~Δ',~\find{\helper{f}{\ell}}~\vec{\var{v}}~(\helper{f}{\ell}~\vec{\var{v}})$.
      We can then recursively solve the proof for $\helper{f}{\ell}$.
    \end{itemize}
  \end{itemize}
  \qed
\end{theorem}

\subsection{Deriving an eliminator}

Once we have the proof of the graph lemma
$Π~Δ,~\find{f}~\bar{Δ}~(\cst{f}~\bar{Δ})$,
we can specialize the eliminator of $\find{f}$ which is of the form:

\[\begin{array}{l}
  Π~(P : Π~Δ,~\fcomp{f}~\bar{Δ} "->" \Prop)
  \vec{(P_{\helper{f}{\ell}} : Π~Δ_{\helper{f}{\ell}},~\fcomp{\helper{f}{\ell}}~\vec{t} "->" \Prop)} \vspace{0.1em}\\
  (f : Π~Γ, \find{f}~\vec{t}~(\cst{f}~\vec{u}) "->"
  P~\vec{t}~(\cst{f}~\vec{u}) "->" \cdots) \\
  \vdots \\
  Π~Δ~(r : \fcomp{f}~\bar{Δ}), \find{f}~\bar{Δ}~r "->" 
  P~\bar{Δ}~r \vspace{0.1em}
\end{array}\]

This eliminator expects not only one proposition depending on the
arguments of the initial call to $\cst{f}$ but also a proposition for
each one of the helpers corresponding to refinement nodes. We can easily 
define the proposition for \helper{f}{(\ell . n)} in terms of the proposition
for $\helper{f}{\ell}$. Each $P_\helper{f}{\ell . n}$ is defined as:

\def\cast#1#2{\mathsf{cast}~#1~#2}

\[\begin{array}{l}
  λ~Δ^x~(x : τ)~Δ_x~(r : \fcomp{f}{(\ell.n)}~\bar{Δ_{\helper{f}{(\ell.n)}}}),
  Π~Ψ~\IndHyps{Ψ}\{\find{f}:=P\},\vspace{0.1em}\\ 
  \quad\quadΠ~H : x = t', P_{\helper{f}{l}}~\bar{Δ^x}~\bar{Δ_x}~(\cast{r}{x}~H)
  \quad \text{where } \absrec{f}{t} = Ψ, t'
\end{array}\]

We abstract on the context of the refinement node with its distinguished
variable $x$ and on a result $r$ for the subprogram. As we know that 
this subprogram is called with a particular refined value $t$, we can
assert the equality $x = t$ and cast the result with this equality to
get back a term of type $\fcomp{\helper{f}{\ell}}~\bar{Δ^x}~\bar{Δ_x}$: we are simply 
doing the inverse of the abstraction of $t$ that happened during the
typechecking of the refinement node. Of course, if $t$ itself contains
recursive calls, we must also abstract by the corresponding $P$
hypotheses.

We want to eliminate not any $\fcomp{f}~\bar{Δ}$ object but specifically
$\cst{f}$ calls.
Using the graph lemma proof we can trivially specialize the conclusion to
$Π~Δ, P~\bar{Δ}~(\cst{f}~\bar{Δ})$

We can also remove the unnecessary hypotheses of the form
$\find{f}~\vec{t}~(\cst{f}~\vec{u})$ appearing in the methods, as
they are all derivable from the graph lemma proof. 

Finally, we can get rid of all the indirection methods as they are of
the form:

\[Π~Δ_{\helper{f}{\ell.n}}~(r : \fcomp{f}~\vec{t}),
  Π~Ψ~\IndHyps{Ψ}{\{\find{f} := P\}},
  P_{\helper{f}{\ell.n}}~\bar{Δ^x}~t~\bar{Δ_x}~r "->"
  P_{\helper{f}{\ell}}~\vec{p}~r\]

These are readily derivable given the definitions of the
$\helper{P}{\ell}$ above: the equality hypothesis for the refinement is 
instantiated by a reflexivity proof, making the cast reduce directly.
We are left with a tautology.

The cleaned up eliminator can be applied directly to any goal depending on
$\cst{f}$, possibly after another generalization by equalities if the
call has concrete, non-variable arguments. The elimination will give as
many goals as there are \Prog{} nodes in the splitting tree (possibly
more than the number of actual user nodes due to overlapping
patterns). The context will automatically be enriched by equalities
witnessing all the refinement information available and of course induction
hypotheses will be available for every recursive call appearing in
these and the right hand sides. This gives rise to a very powerful tool
to write proofs on our programs, and a lightweight one at the same time:
all the details of the splitting, refinement and recursion are
encapsulated in the eliminator.

% Consider for example the following definition of
% \coqdocdefinition{filter} on a polymorphic list:

% \begin{coqdoccode}
% \coqdoceol
% \coqdocnoindent
% \coqdockw{Equations} \coqdef{filterind.filter}{filter}{\coqdocdefinition{filter}} \{\coqdocvar{A}\} (\coqdocvar{l} : \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{list}{\coqdocinductive{list}} \coqdocvariable{A}) (\coqdocvar{p} : \coqdocvariable{A} \ensuremath{\rightarrow} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{bool}{\coqdocinductive{bool}}) : \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{list}{\coqdocinductive{list}} \coqdocvariable{A} :=\coqdoceol
% \coqdocnoindent
% \coqref{filterind.filter}{\coqdocdefinition{filter}} \coqdocvar{A} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{nil}{\coqdocconstructor{nil}} \coqdocvar{p} := \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{nil}{\coqdocconstructor{nil}} ;\coqdoceol
% \coqdocnoindent
% \coqref{filterind.filter}{\coqdocdefinition{filter}} \coqdocvar{A} (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{cons}{\coqdocconstructor{cons}} \coqdocvar{a} \coqdocvar{l}) \coqdocvar{p} \coqdockw{with} \coqdocvariable{p} \coqdocvariable{a} := \{\coqdoceol
% \coqdocindent{1.00em}
% \ensuremath{|} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{true}{\coqdocconstructor{true}} := \coqdocvariable{a} :: \coqref{filterind.filter}{\coqdocdefinition{filter}} \coqdocvariable{l} \coqdocvariable{p} ;\coqdoceol
% \coqdocindent{1.00em}
% \ensuremath{|} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{false}{\coqdocconstructor{false}} := \coqref{filterind.filter}{\coqdocdefinition{filter}} \coqdocvariable{l} \coqdocvariable{p} \}.\coqdoceol
% \coqdocnoindent
% \end{coqdoccode}


% This closes our presentation of the \Equations implementation. Having
% a concrete splitting tree representation gives us the ability to easily
% derive support code for the function definitions, and is one of the
% unexpected benefits of the external approach. We will now demonstrate
% how this support code can be put to use.

%%% Local Variables: 
%%% mode: latex
%%% TeX-PDF-mode: t
%%% TeX-master: "equations"
%%% End: 