\section{Dependent pattern-matching compilation redux}
\label{sec:sketch-patt-match}

The idea of writing pattern-matching equations over inductive families
goes back to Coquand \cite{coquand92baastad}. He introduced the idea of checking
that a set of equations formed an exhaustive \emph{covering} of a
signature. From this covering one can build an efficient case tree in
the standard way \cite{DBLP:conf/fpca/Augustsson85}.

The interesting addition of dependent pattern-matching over simply-typed
pattern-matching is the fact that some constructors need not be
considered because the filtered object's type guarantees that they
could not have been built with it. Moreover, as each constructor refines
the indices of a filtered object and as we are considering equations
that can have multiple patterns, refinement may have effects on the
values or types of other matched objects. This means that each
constructor adds static information to the problem, and this process 
can be used ad libitum, as exemplified by the definition of
\coqdoccst{diag} below:

\begin{coqdoccode}
\coqdocemptyline
\coqdocnoindent
\coqdockw{Equations} \coqdef{intro.diag}{diag}{\coqdocdefinition{diag}} \{\coqdocvar{A} \coqdocvar{n}\} 
(\coqdocvar{v} : \coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{vector}{\coqdocinductive{vector}} (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{vector}{\coqdocinductive{vector}} \coqdocvariable{A} \coqdocvariable{n}) \coqdocvariable{n}) : \coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{vector}{\coqdocinductive{vector}} \coqdocvariable{A} \coqdocvariable{n} :=\coqdoceol
\coqdocnoindent
\coqref{intro.diag}{\coqdocdefinition{diag}} \coqdocvar{A} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{O}{\coqdocconstructor{O}} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{Vnil}{\coqdocconstructor{Vnil}} := \coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{Vnil}{\coqdocconstructor{Vnil}} ;\coqdoceol
\coqdocnoindent
\coqref{intro.diag}{\coqdocdefinition{diag}} \coqdocvar{A} (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{S}{\coqdocconstructor{S}} \coqdocvar{n}) (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{Vcons}{\coqdocconstructor{Vcons}} (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{Vcons}{\coqdocconstructor{Vcons}} \coqdocvar{a} \coqdocvar{n} \coqdocvar{v}) \coqdocvar{n} \coqdocvar{v'}) := 
\coqexternalref{http://coq.inria.fr/stdlib/Coq.Bool.Bvector}{Vcons}{\coqdocconstructor{Vcons}} \coqdocvariable{a} (\coqref{intro.diag}{\coqdocdefinition{diag}} (\coqref{intro.vmap}{\coqdocdefinition{vmap}} \coqref{intro.vtail}{\coqdocdefinition{vtail}} \coqdocvariable{v'})).\coqdoceol
\coqdocnoindent
\end{coqdoccode}

We pattern match on a square matrix of size n by n and compute its
diagonal. Only two cases need to be considered: either the matrix is
empty and so is its diagonal, or the matrix has n + 1 rows made of
vectors of size n + 1 and we can extract the element at the top left of
the matrix and build the rest of the diagonal recursively.

\vspace{-1em}

\subsubsection{Internal vs. external approaches}
\label{sec:intern-vs.-extern}

There exist two main approaches to adding dependent pattern matching to
a dependent type theory. One is to bake in the high-level pattern
matching construct and make the associated coverage checking and 
unification procedure part of the core system. This is essentially a
shallow approach: one works directly in the metalanguage of the 
system's implementation and avoids building witnesses for the covering
and unification. The disadvantages of the external approach are that
it makes the trusted code base larger and limits the extensibility of 
the system: adding a new pattern matching construct like with-clauses 
requires to modify the kernel's code. \Agda implements pattern-matching
this way, and there is a proposal to extend \Coq in a similar way
\cite{conf/types/BarrasCGHS08}. 

The internal approach takes a different path. In this case we use the 
type theory itself to explain why a definition is correct,
essentially building a witness of the covering in terms of the 
simpler existing constructs on inductive families. This is the path 
chosen by \cite{DBLP:conf/birthday/GoguenMM06}, and the way \Epigram
implements pattern-matching. One advantage is that the compiler needs
not to be trusted: it elaborates a program that can be checked
independently in the core type theory. By taking an elaboration
viewpoint, it is also much easier to extend the system with new features
that can also be compiled away to the core type theory. Our 
mantra (after McBride) is that type theory is enough to explain
high-level programming constructs. 

Our implementation closely follows the scheme from
\cite{DBLP:conf/birthday/GoguenMM06}, its originality comes mainly from
a number of design choices that we will explain in detail.
We will not present here the whole formal development of pattern-matching
compilation as is done in \cite{DBLP:conf/birthday/GoguenMM06} but we
will introduce the main structures necessary to describe our
contributions.

% Some are
% dictated by our type theory of choice, the (predicative) Calculus of
% Inductive Constructions (\S \ref{sec:dealing-with-k}), some are driven
% by an aspiration to extensibility (\S \ref{sec:few-constructions}), 
% heavily using type classes \cite{sozeau.Coq/classes/fctc} and the tactic
% language and finally others are driven by performance considerations (\S
% \ref{sec:recursion}). 

The compilation process starts from a signature and a set of clauses
given by the user, constructed from the grammar given in
figure \ref{fig:usergram}.
\vspace{-1em}

\begin{figure}[h]
\center$\figdefs$
\caption{Definitions and user clauses} 
\label{fig:usergram}
\end{figure}
\vspace{-1em}

A program is given as a tuple of a (globally fresh) identifier, 
a signature and a set of user clauses. The signature is simply a list of
bindings and a result type. The purposed type of the function 
\coqdoccst{f} is then $Π~Γ, τ$. Each user clause comprises a set of
patterns that will match the bindings $Γ$ and a right hand side which
can either be a simple term (program node), an empty node indicating
that the type of variable \coqdoccst{x} is uninhabited or a refinement
node adding a pattern to the problem, strutinizing the value of $t$.

\paragraph{Notations and terminology}
We will use the notation $\bar{Δ}$ to denote the set of variables bound by
an environment Δ, in the order of declarations.
An \emph{arity} is a term of the form $Π~Γ, s$ where $s$ is a sort.
A sort (or kind) can be either $\Prop$ (categorizing propositions) or
$\Type$ (categorizing computational types, like \ind{bool}). An
arity is hence always a type.
We consider inductive families to be defined in a (elided) global context
by an arity $\ind{I} : Π~Δ, s$ and constructors 
$\vec{\cstr{I}_i : Π~Γ_i, \ind{I}~\vec{t}}$. Although \CIC distinguishes
between parameters and indices and our implementation does too, we will
not distinguish them in the presentation for the sake of simplicity.

\subsubsection{Searching for a covering}
\label{sec:searching-covering}

The goal of the compiler is to produce a proof that the user clauses form
an exhaustive covering of the signature, compiling away nested
pattern-matchings to simple case splits. As we have multiple patterns to
consider and allow overlapping clauses, there may be more than one way
to order the case splits to achieve the same results. We use
inaccessible patterns as in \Agda to help recover a sense of what needs to be
destructed and what is statically known to have a particular value,
but overlapping clauses force the compilation to be phrased as a search
procedure. As usual, we recover a deterministic
semantics using a first-match rule when two clauses overlap.

\begin{figure}[h]
\center$\figsplit$
\caption{Context mappings and splitting trees}
\label{fig:split}
\end{figure}

The search for a covering works by gradually refining a
\emph{programming problem} \prob{Δ}{\vec{p}}{Γ} and building a
splitting tree. A programming problem, or context mapping (fig. \ref{fig:split}),
is a substitution from Δ to Γ, associating to each variable in Γ a
pattern $p$ typable in Δ. We start the search with the problem
\prob{Γ}{\bar{Γ}}{Γ}, i.e. the identity substitution on Γ and
the list of user clauses. We define for $\cst{f}$ with signature $Π~Δ, τ$
the \cst{f}-computation type $\fcomp{f}~Δ := τ$ and consider the type of
the function to be $Π~Δ, \fcomp{f}~Δ$ from now on. We will use this
computation type during compilation to precisely keep track of recursive
calls and to interface with tactics. A splitting can either be:
\begin{itemize}
\item A $\Split{\prob{Δ}{\vec{p}}{Γ}}{\var{x}}{(s?)^n}$ node denoting that
  the variable \var{x} is an object of an inductive type with $n$
  constructors and that splitting it in context Δ will generate $n$ subgoals
  which are covered by the optional subcoverings $s$. When the type of
  \var{x} does not unify with a particular constructor's type the
  corresponding splitting is empty.
\item A $\Compute{\prob{Δ}{\vec{p}}{Γ}}{rhs}$ node, where the right hand side can be either:
  \begin{itemize}
  \item A $\Prog{t}$ node denoting a leaf of the tree with program $t$.
  \item A $\Refine{t}{c'}{label}{s}$ node corresponding to a with rule introducing a
    pattern for $t$ with $s$ covering the new problem $c'$. The $label$
    is a fresh identifier that will be used to define auxiliary definitions.
  \end{itemize}
\end{itemize}
\newcommand{\Matches}[2]{\textsc{Match}(#1,#2)}

\vspace{-1em}

\begin{figure}[h]
\center$\begin{array}{lcl}
  \Matches{\var{x}}{p} & \coloneqq & \Uparrow \{x := p\} \\
  \Matches{\constr{C}~\vec{p}}{\constr{C}~\vec{q}} & \coloneqq & \Matches{\vec{p}}{\vec{q}} \\
  \Matches{\constr{C}~\_}{\constr{D}~\_} & \coloneqq & \Downarrow \\
  
  \Matches{\constr{C}~\vec{p}}{\var{y}} & \coloneqq & \Rightarrow~\{\var{y}\} \\
  
  \Matches{\innac{t}}{\_} & \coloneqq & \Uparrow \emptyset \\
  & & \\
  \Matches{ε}{ε} & \coloneqq & \Uparrow ε \\
  \Matches{p₀; \vec{p}}{q₀; \vec{q}} & \coloneqq & \Matches{p₀}{q₀}
  \cup \Matches{\vec{p}}{\vec{q}}
\end{array}\hfill
\begin{array}{lcl}
  \Uparrow s~\cup \Uparrow s' & \coloneqq & \Uparrow (s \cup s') \\
  \Rightarrow s~\cup \Rightarrow s' & \coloneqq & \Rightarrow (s \cup
  s') \\
  \Downarrow \cup~\_ `| \_~\cup \Downarrow & \coloneqq & \Downarrow \\
  \Rightarrow s~\cup \_ & \coloneqq &
  \Rightarrow s \\
  \_~\cup \Rightarrow s & \coloneqq & \Rightarrow s
\end{array}$
\caption{Matching patterns}
  \label{fig:matches}
\end{figure}

\vspace{-1em}

Recursively, we will try to match the user 
patterns of each clause with the current problem \prob{Δ}{\vec{p}}{Γ}.
Matching patterns \vec{q} from the a user clause and 
patterns \vec{p} from the current programming problem can either
fail ($\Downarrow$), succeed ($\Uparrow s$) returning a variable
substitution $s$ from \vec{q} to \vec{p} or get stuck ($\Rightarrow s$)
returning a set of variables from \vec{p} that needs further splitting
to match the user patterns in \vec{q}.

\begin{itemize}
\item If the clause does not match a particular problem
  we try the next one, if there are no clauses left
  we have a non-exhaustive pattern-matching.

\item If the problem is stuck on the clause, we
  try to recursively find a splitting after refining a stuck variable $x$,
  creating subproblems that correspond to an instantiation of the
  variable with each possible constructor.
  We build a $\Split{c}{x}{s}$ node from the resulting set of
  splittings if all succeed, or try the next stuck variable.

\item If the clause matches we get back a substitution from the user
  clause variables to Δ, so we can typecheck right-hand side terms in
  environment Δ. We look at the right-hand side and decide:

  \begin{itemize}
  \item If it is a program user node, we simply typecheck the program
    and build a \Prog{t} node.
  \item If it is an empty node ($\coloneqq\!\!\!\verb|!|~\var{x}$), we
    refine \var{x} and check that this produces no subproblems, building a
    \texttt{Split} node.
  \item If it is a with node ($\Leftarrow t \Rightarrow \{ \vec{c} \}$),
    we typecheck $t$ in $Δ$ finding its type $τ_Δ$. We then strengthen 
    the context $Δ$ for $t$, giving us the minimal context $Δ^t$ to
    typecheck $t$ and the remaining context $Δ_t$. This strengthening 
    is in fact a context mapping 
    \prob{Δ^t, \var{x_t} : τ_Δ, Δ_t}{str}{Δ, \var{x_t} : τ_Δ}.
    We can now abstract $t$ from the remaining context to get 
    a new context: $Δ^t, \var{x_t} : τ_Δ, Δ_t[t/\var{x_t}]$. 
    We check that this context is well-typed after the abstraction, 
    which might not be the case. We also abstract $t$ in the goal 
    type and recheck it before searching for a covering of the identity 
    substitution of $Δ^t, \var{x_t} : τ_Δ, Δ_t[t/\var{x_t}$ using 
    updated user clauses \vec{c}. 
    The clauses are actually reordered to match the strengthening:
    each $c_i$ must be of the form $\vec{p}_i~p_i^x$ where $\vec{p}_i$
    matches $\vec{p}$. The matching gives us a substitution from the
    variables of $\vec{p}$, the patterns at the with node, to new 
    user patterns. We can easily make new user clauses matching the 
    strengthened context $Δ^t, \var{x_t} : τ_Δ, Δ_t[t/\var{x_t}]$ 
    by associating to each variable of $Δ$ its associated user pattern 
    and using $p_i^x$ for the new pattern.
    The result of the covering will then be a splitting $s$ for
    the problem $c' = \prob{Δ^t, \var{x_t} : τ_Δ, Δ_t[t/\var{x_t}]}
    {\bar{Δ^t}, \var{x_t}, \bar{Δ_t}}{Δ^t, \var{x_t} : τ_Δ,
      Δ_t[t/\var{x_t}]}$ from which we can build a
    $\Refine{t}{c'}{\ell.n}{s}$ node.
    Compiling this term will give us a term of type
    $Π~Δ^t~(\var{x_t} : τ_Δ)~Δ_t[t/\var{x_t}], τ_f[t/\var{x_t}]$.
    We can apply this term to $\bar{Δ^t}, t, \bar{Δ_t}$ to recover a
    term of type $τ_f$ in the original $Δ$ context, providing a witness
    for the initial \prob{Δ}{\vec{p}}{Γ} problem.
    Consider for example the following definition:

\begin{coqdoccode}
\coqdoceol
\coqdocnoindent
\coqdockw{Equations} \coqdef{filter.filter}{filter}{\coqdocdefinition{filter}} \{\coqdocvar{A}\} (\coqdocvar{l} : \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{list}{\coqdocinductive{list}} \coqdocvariable{A}) (\coqdocvar{p} : \coqdocvariable{A} \ensuremath{\rightarrow} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{bool}{\coqdocinductive{bool}}) : \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{list}{\coqdocinductive{list}} \coqdocvariable{A} :=\coqdoceol
\coqdocnoindent
\coqref{filter.filter}{\coqdocdefinition{filter}} \coqdocvar{A} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{nil}{\coqdocconstructor{nil}} \coqdocvar{p} := \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{nil}{\coqdocconstructor{nil}} ;\coqdoceol
\coqdocnoindent
\coqref{filter.filter}{\coqdocdefinition{filter}} \coqdocvar{A} (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{cons}{\coqdocconstructor{cons}} \coqdocvar{a} \coqdocvar{l}) \coqdocvar{p} \coqdockw{with} \coqdocvariable{p} \coqdocvariable{a} := \{\coqdoceol
\coqdocnoindent
\coqref{filter.filter}{\coqdocdefinition{filter}} \coqdocvar{A} (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{cons}{\coqdocconstructor{cons}} \coqdocvar{a} \coqdocvar{l}) \coqdocvar{p} \coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{true}{\coqdocconstructor{true}} := \coqdocvariable{a} :: \coqref{filter.filter}{\coqdocdefinition{filter}} \coqdocvariable{l} \coqdocvariable{p} ;\coqdoceol
\coqdocnoindent
\coqref{filter.filter}{\coqdocdefinition{filter}} \coqdocvar{A}
(\coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{cons}{\coqdocconstructor{cons}}
\coqdocvar{a} \coqdocvar{l}) \coqdocvar{p}
\coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{false}{\coqdocconstructor{false}}
:= \coqref{filter.filter}{\coqdocdefinition{filter}} \coqdocvariable{l}
\coqdocvariable{p} \}.\coqdoceol
\coqdocnoindent
\end{coqdoccode}

    When interpreting the \coqdockw{with} node, the patterns of the inner clauses
    are transformed to match the variables
    \coqdocvar{A} \coqdocvar{a} \coqdocvar{l} \coqdocvar{p} bound at the
    \coqdockw{with}
    node and their additional pattern for \coqdocvar{p} \coqdocvar{a}.

    The compiled term built from this covering will have type
    \[Π \coqdocvar{A}~\coqdocvar{a}~\coqdocvar{l}~\coqdocvar{p}~(\var{b} :
    \ind{bool}), \fcomp{filter}~\coqdocvar{A}~
    (\coqexternalref{http://coq.inria.fr/stdlib/Coq.Init.Datatypes}{cons}{\coqdocconstructor{cons}}~
    \coqdocvar{a}~\coqdocvar{l})~\coqdocvar{p}\] We can then
    instantiate \var{b} with $\var{p}~\var{a}$ to build a term in the initial
    \coqdocvar{A}, \coqdocvar{a}, \coqdocvar{l}, \coqdocvar{p} context.
  \end{itemize}
\end{itemize}

This is a basic overview of the algorithm for type-checking
pattern-matching definitions as described in \cite{norell:thesis},
except for the treatment of innaccessible patterns we omitted for
brevity.
In our case however we not only check that pattern-matchings are
well-formed, we also produce witnesses for this compilation in the core
language, following \cite{DBLP:conf/birthday/GoguenMM06}. 
Now that we have compiled the program to a simplified splitting tree, 
we just need to construct a mapping from splittings to \Coq terms. 
We already explained how $\Refine{c}{x}{\ell}{s}$ nodes are compiled, and
\Prog{t} nodes are trivially compiled, so we just need to map
\texttt{Split} nodes.

\subsection{A few constructions}
\label{sec:few-constructions}

The dependent pattern-matching notation acts as a high-level interface 
to a unification procedure on the theory of constructors and
uninterpreted functions. Our main building block in the compilation
process is hence a mechanism to produce witnesses for the resolution of
constraints in this theory, and use these to compile \texttt{Split}
nodes. The proof terms will be formed by applications of simplification 
combinators dealing with substitution and proofs of injectivity and
discrimination of constructors, their two main properties. 

The design of this simplifier is based on the ``specialization by
unification'' method developed in
\cite{DBLP:conf/types/McBride00,mcbride:concon}. 
The problem we face is to eliminate an object \var{x} of type $\ind{I}
\vec{t}$ in a goal $Γ \vdash τ$ potentially depending on $x$. We want
the elimination to
produce subgoals for the allowed constructors of this family instance.
To do that, we generalize the goal by fresh variables 
$Δ~(\var{x'} : \ind{I}~\bar{Δ})$ and a set of equations asserting that
$\var{x'}$ is equal to $\var{x}$, giving us a new, equivalent goal: 
\[ Δ, \var{x'} : \ind{I}~\bar{Δ}, Γ \vdash \vec{\bar{Δ_i} \simeq \bar{t_i}} "->" \var{x} \simeq \var{x'}
"->" τ \]

Note that the equations relate terms that may be in different types due
to the fresh indices, hence we use heterogeneous equality $\simeq$ to
relate them. We can apply the standard eliminator for \ind{I} on $x'$ in
this goal to get subgoals corresponding to all its constructors, all
starting with a set of equations relating the indices $t$ of the
original instance to the indices of the constructor. We use a recursive
tactic to simplify these equalities, solving the impossible cases
automatically. Its completeness is asserted in
\cite{DBLP:conf/birthday/GoguenMM06}: at the end of specialization we
get refined goals where the initial $x$ has been substituted by the
allowed constructors only.

Our tactic relies on a set of
combinators for simplifying equations in the theory of constructors, most
of which are just rephrasings of the substitution principles for
\people{Leibniz} and heterogeneous equality. The only interesting bit is a
simplifier for equalities between constructors. We need a tactic that
can simplify any equality $\cstr{C} \vec{t} = \cstr{D} \vec{u}$,
either giving us equalities between arguments $\vec{t}$ and $\vec{u}$ that can be
further simplified or deriving a contradiction if $\cstr{C}$ is
different from $\cstr{D}$. McBride {\it et al.} \cite{mcbride:concon} describe a generic method to
derive such an eliminator that we adapted to $\Coq$.
For any (computational) inductive type $\ind{I} : Π~Γ, \Type$, we can derive a
transformer $\cst{NoConfusion}_\ind{I} : Π~Γ~(P : \Type), \ind{I}~\bar{Γ} "->"
\ind{I}~\bar{Γ} "->" \Type$ that 
describes how to simplify the goal $P$ under the assumption that the two 
instances of $\ind{I}~\bar{Γ}$ are equal. E.g., for natural numbers we define:

\input{noconf.coq}

\subsubsection{Dealing with K}
\label{sec:dealing-with-k}

There is one little twist in our simplifier, due to the fact that \Coq does
not support the principle of ``Uniqueness of Identity Proofs'', also
referred to as \people{Streicher}'s K axiom \cite{Streicher91}, which is
necessary to compile dependent pattern-matchings:

\coqdocemptyline
\coqdockw{Axiom} \coqexternalref{http://coq.inria.fr/distrib/trunk/stdlib/Coq.Logic.ProofIrrelevance}{ProofIrrelevanceTheory.EqdepTheory.UIPrefl}{\coqdoclemma{UIP\_refl}}
: \ensuremath{\forall} (\coqdocvar{U} : \coqdockw{Type}) (\coqdocvar{x}
: \coqdocvariable{U}) (\coqdocvar{p} : \coqdocvariable{x} =
\coqdocvariable{x}), \coqdocvariable{p} = \eqrefl
\coqdocemptyline

This principle allows us to simplify a goal depending on a proof $p$ of
$\var{x} = \var{x}$ by substituting the sole constructor \eqrefl{} for
$p$. As we are outside the kernel, we can easily make use of this
axiom to do the simplifications, but this means that some of our
definitions will not be able to reduce to their expected normal forms: 
they are not closed in the empty context anymore. We will tame this
problem by providing the defining equations as rewrite rules
once a function is accepted, making use of the axiom again to prove
these. 

It is notorious that using rewriting instead of the raw system reduction
during proofs is much more robust and lends itself very well to
automation. Hence we only lose the ability to compute with these
definitions inside \Coq itself, for example as part of reflexive
tactics. At least two proposed extensions to \Coq allow to derive this
principle without any axioms: an extension to make dependent
pattern-matching more powerful with respect to indices \cite{conf/types/BarrasCGHS08} and 
the addition of proof-irrelevance. Having them would make \Equations
only more useful. Note that extracted terms do not suffer from this fact
as propositions like equality are erased.

%  If we use the extraction mechanism of \Coq %\cite{Let2008} 
% that produces
% terms in a standard functional language like \ML or \Haskell by removing
% all the logical parts of terms, this problem simply disappears.

\input{recursion}
%%% Local Variables: 
%%% mode: latex
%%% TeX-PDF-mode: t
%%% TeX-master: "equations"
%%% End: 