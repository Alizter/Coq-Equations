\section{Implementing dependent pattern-matching}

The idea of writting pattern-matching equations over inductive families
goes back to \cite{coquand92baastad}. He introduced the idea of checking
that a set of equations formed an exhaustive \emph{covering} of a
signature. From this covering one can build an efficient case-tree in
the standard way \cite{DBLP:conf/fpca/Augustsson85}.

The interesting addition of dependent pattern-matching over simply-typed
pattern-matching is the fact that some constructors need not be
considered because the filtered object's type guarantees that they
couldn't have been built with it. Moreover, as each constructor refines
the indices of a filtered object and as we are considering equations
that can have multiple patterns, refinement may have effect on the
values or types of other matched objects. This means that each
constructor adds static information to the problem, and this process 
can be used ad libitum, as examplified by the definition of
\coqdoccst{diag} above. 

\subsection{Internal vs. external approaches}

There exist two main approaches to adding dependent pattern matching to
a dependent type theory. One is to bake in the high-level pattern
matching construct and make the associated coverage checking and 
unification procedure part of the core system. This is essentially a
shallow approach: one works directly in the metalanguage of the 
systems implementation and avoids building witnesses for the covering
and unification. The disadvantages of the internal approach are that
it makes the trusted code base larger and limits the extensibility of 
the system: adding a new pattern matching construct like with clauses 
requires to modify the kernel's code. \Agda implements pattern-matching
like this, and there is a proposal to extend \Coq in a similar way
\cite{CoqTYPES09}. 
The external approach takes a different path. In this case we use the 
type theory itself to explain why a definition is correct,
essentially building a witness of the covering in terms of the much
simpler existing constructs on inductive families. This is the path 
chosen by \cite{DBLP:conf/birthday/GoguenMM06}, and the way \Epigram
implements pattern-matching. One advantage is that the compiler needs
not to be trusted: it elaborates a program that can be checked
independently in the core type theory. By taking an elaboration
viewpoint, it is also much easier to extend the system with new features
that can also be compiled away to the core type theory. Our 
mantra (after McBride) is that type theory is enough to explain
high-level programming constructs. 

Our implementation closely follows the scheme from
\cite*{DBLP:conf/birthday/GoguenMM06}, its originality comes mainly from
a number of design choices that we will explain in detail. Some are
dictated by our type theory of choice, the (predicative) Calculus of
Inductive Constructions (\S \ref{sec:dealing-with-k}), some are driven
by an aspiration to extensibility (\S \ref{sec:few-constructions}), 
heavily using type classes \cite{sozeau.Coq/classes/fctc} and the tactic
language and finaly others are driven by performance considerations (\S
\ref{sec:recursion}). We will not detail here the whole formal
development of pattern-matching compilation as is done in 
\cite*{DBLP:conf/birthday/GoguenMM06} but we will introduce the main
structures necessary to describe our contributions.

\subsection{A sketch of pattern-matching compilation}

The compilation process starts from a signature and a set of clauses
given by the user, constructed from the following grammar:

\def\vec#1{\protect\overrightarrow{#1}}
\newcommand{\innac}[1]{\texttt{?(} #1 \texttt{)}}

\begin{figure}[h]
$\begin{array}{llcl}
  \texttt{term}, \texttt{type} & t, ~τ & \Coloneqq &
  \coqdocvar{x} `| λ \coqdocvar{x} : τ, t `| Π \coqdocvar{x} : τ, τ' `|
  \ldots \\
  \texttt{binding} & d & \Coloneqq & (\coqdocvar{x}~:~τ) `|
  (\coqdocvar{x}~\coloneqq~t~:~τ) \\
  \texttt{context} & Γ, Δ & \Coloneqq & \vec{d} \\
  \texttt{program} & prog & \Coloneqq & \coqdoccst{f}~Γ~:~τ~\coloneqq~\vec{c} \\
  \texttt{user clause} & c & \Coloneqq & \coqdoccst{f}~\vec{p}~n \\
  \texttt{pattern} & p,~q & \Coloneqq & x 
  `| \coqdocconstr{C}~\vec{p} 
  `| \innac{t} \\
  \texttt{user node} & n & \Coloneqq &
  \coloneqq~t~|\coloneqq\!\!\verb|!|~\coqdocvar{x}~
  |\Leftarrow t \Rightarrow \{~\vec{c}~\}
\end{array}$
\caption{Definitions and user clauses} 
\end{figure}

\paragraph{Notations and terminology}
We will use the notation $\bar{Δ}$ to denote the set of variables bound by
an environment Δ, in the order of declarations.
An \emph{arity} is a term of the form $Π~Γ, s$ where $s$ is a sort.
A sort (or kind) can be either $\Prop$ (categorizing propositions) or
$\Type$ (categorizing computational types, like \ind{bool}). An
arity is hence always a type.
We consider inductive families to be defined in a (elided) global context
by an arity $\ind{I} : Π~Δ, τ$ and constructors 
$\vec{\cstr{I}_i : Π~Γ_i, \ind{I}~\vec{t}}$. Although \Coq distinguishes
between parameters and indices and our implementation does too, we will
not distinguish them in the presentation for the sake of simplicity.

A program is given as a tuple of a (globally fresh) identifier, 
a signature and a set of user clauses. The signature is simply a list of
bindings and a result type. The purposed type of the function 
\coqdoccst{f} is then $Π~Γ, τ$. Each user clause comprises a set of
patterns that will match the bindings $Γ$ and a right hand side which
can either be a simple term (program node), an empty node indicating
that the type of variable \coqdoccst{x} is uninhabited or a refinement
node adding a pattern to the problem, structinizing the value of $t$.

\subsubsection{Searching for a covering}

The goal of the compiler is to produce a proof that the user clauses form
an exhaustive covering of the signature, compiling away nested
pattern-matchings to simple case splits. As we have multiple patterns to
consider and allow overlapping clauses, there may be more than one way
to order the case splits to achieve the same results. As we have seen
before, inaccessible patterns help recover a sense of what needs to be
destructed and what is statically known to have a particular value, and
the order is irrelevant if the patterns are not depending on each
other. On the other hand, overlapping clauses force the compilation to
be phrased as a search procedure. As usual, we recover a deterministic
semantics using a first-match rule when two clauses overlap.

\newcommand{\prob}[3]{\ensuremath{#1 \vdash #2 : #3}}

The search for a covering works by gradually refining a
\emph{programming problem} \prob{Δ}{\vec{p}}{Γ} and building a
splitting tree. A programming problem, or context mapping (fig. \ref{fig:split}),
is a substitution from Δ to Γ, associating to each variable in Γ a
pattern $p$ typable in Δ. We start the search with the problem
\prob{Γ}{\bar{Γ}}{Γ}, i.e. the identity substitution on Γ, the return
type $τ_\cst{f}$ and the list of user clauses. The splitting tree is 
defined by the grammar:

\begin{figure}[h]
$\begin{array}{llcl}
  \texttt{context map} & c & \Coloneqq & Δ \vdash \vec{p} : Γ \\
  \texttt{splitting} & spl & \Coloneqq &
  \Split{c}{\var{x}}{(spl?)^n}
  `| \Compute{c}{rhs} \\
  
  \texttt{node} & rhs & \Coloneqq & \Prog{t}
  `| \Empty{\var{x}}
  `| \Refine{t}{c}{\cst{f}}{spl} \\
\end{array}$
\caption{Context mappings and splitting trees}
\label{fig:split}
\end{figure}

A splitting tree is either:
\begin{itemize}
\item A $\Split{\prob{Δ}{\vec{p}}{Γ}}{\var{x}}{s^n}$ node denoting that
  splitting the variable \var{x} in context Δ will generate $n$ subgoals
  which are covered by the subcoverings $s$. 
\item A $\Compute{c}{rhs}$ node, where the right hand side can be either:
  \begin{itemize}
  \item A $\Prog{t}$ node denoting a leaf of the tree with program $t$.
  \item A $\Refine{t}{c'}{label}{s}$ node corresponding to a with rule introducing a
    pattern for $t$ with $s$ covering the new problem $c'$. The $label$
    is a fresh identifier that will be used to define auxilliary definitions.
  \end{itemize}
\end{itemize}

Recursively, we will try to match the user clauses with
the current problem. Matching is defined in figure \ref{fig:matches}.

\newcommand{\Matches}[2]{\textsc{Matches}(#1,#2)}
\begin{figure}[h]
  $\begin{array}{lcl}
    \Matches{ε}{ε} & \coloneqq & \Uparrow ε \\
    \Matches{p₀; \vec{p}}{q₀; \vec{q}} & \coloneqq & \Matches{p₀}{q₀} \cup
    \Matches{\vec{p}}{\vec{q}} \\
    
    \Matches{\var{x}}{p} & \coloneqq & \Uparrow \{x := p\} \\
    \Matches{\constr{C}~\vec{p}}{\constr{C}~\vec{q}} & \coloneqq & \Matches{\vec{p}}{\vec{q}} \\
    \Matches{\constr{C}~\_}{\constr{D}~\_} & \coloneqq & \Downarrow \\
    
    \Matches{\constr{C}~\vec{p}}{\var{y}} & \coloneqq & \Rightarrow~\{\var{y}\} \\
    
    \Matches{\innac{t}}{\_} & \coloneqq & \Uparrow \emptyset \\

    & &  \\
    \Uparrow s~\cup \Uparrow s' & \coloneqq & \Uparrow (s \cup s') \\
    \Rightarrow s~\cup \Rightarrow s' & \coloneqq & \Rightarrow (s \cup
    s') \\
    \Downarrow \cup~\_ `| \_~\cup \Downarrow & \coloneqq & \Downarrow \\
    (\Rightarrow s~\cup \_) `| (\_~\cup \Rightarrow s) & \coloneqq & \Rightarrow s
  \end{array}$
  \caption{Matching patterns}
  \label{fig:matches}
\end{figure}

Matching patterns \vec{p} from the a user clause and 
patterns \vec{q} from the current programming problem can either
fail ($\Downarrow$), succeed ($\Uparrow s$) returning a variable
substitution $s$ from \vec{p} to \vec{q} or get stuck ($\Rightarrow s$)
returning a set of variables from \vec{q} that needs further splitting
to match the user patterns in \vec{p}. 

\begin{itemize}
\item If none of the clauses match a particular problem
  we have a non-exhaustive pattern-matching. 

\item If the problem is stuck, we
  try to recursively find a splitting after refining a stuck variable,
  doing a dependent elimination on the object to produce subproblems
  corresponding to an instantiation of the variable with each allowed
  constructor.

\item If some clauses match we choose the first one. Once a clause has
  been chosen, supposing the
  current programming problem is \prob{Δ}{\vec{p}}{Γ}, matching gives us a
  substitution from the user clause variables to Δ, so we can typecheck
  right hand side terms in environment Δ. We look at the right-hand side
  and decide:

  \begin{itemize}
  \item If it is a program user node, we simply typecheck the program and build
    a \Prog{t} node.
  \item If it is an empty node ($\coloneqq\!\!\!\verb|!|~\var{x}$), we
    refine \var{x} and check that this produces no subproblems, building a
    \texttt{Split} node.
  \item If it is a with node ($\Leftarrow t \Rightarrow \{ \vec{c} \}$),
    we typecheck $t$ in $Δ$ finding its type $τ_Δ$. We then strengthen 
    the context $Δ$ for $t$, giving us the minimal context $Δ^t$ to
    typecheck $t$ and the remaining context $Δ_t$. This strengthening 
    is in fact a context mapping 
    \prob{Δ^t, \var{$x_t$} : τ_Δ, Δ_t}{str}{Δ, \var{$x_t$} : τ_Δ}.
    We can now abstract $t$ from the remaining context to get 
    a new context: $Δ^t, \var{$x_t$} : τ_Δ, Δ_t[t/\var{$x_t$}]$. 
    We check that this context is well-typed after the abstraction, 
    which might not be the case. We also abstract $t$ in the goal 
    type and recheck it before searching for a covering of the identity 
    substitution of $Δ^t, \var{$x_t$} : τ_Δ, Δ_t[t/\var{$x_t$}$ using 
    updated user clauses \vec{c}. 
    The clauses are actually reordered to match the strengthening:
    each $c_i$ must be of the form $\vec{p}_i~p_i^x$ where $\vec{p}_i$
    matches $\vec{p}$. The matching gives us a substitution from the
    variables of $\vec{p}$, the patterns at the with node, to new 
    user patterns. We can easily make new user clauses matching the 
    strengthened context $Δ^t, \var{$x_t$} : τ_Δ, Δ_t[t/\var{$x_t$}]$ 
    by associating to each variable of $Δ$ its associated user pattern 
    and using $p_i^x$ for the new pattern. 
    The result of the covering will then be an exhaustive case-split for
    the problem \prob{Δ^t, \var{$x_t$} : τ_Δ, Δ_t[t/\var{$x_t$}]}
    {\bar{Δ^t}, \var{$x_t$}, \bar{Δ_t}}{Δ^t, \var{$x_t$} : τ_Δ,
      Δ_t[t/\var{$x_t$}]}, hence a term of type
    $Π~Δ^t~(\var{$x_t$} : τ_Δ)~Δ_t[t/\var{$x_t$}], τ_f[t/\var{$x_t$}]$.
    We can apply this term to $\bar{Δ^t}, t, \bar{Δ_t}$ to recover a 
    term of type $τ_f$ in the original $Δ$ context, providing a covering
    for the initial \prob{Δ}{\vec{p}}{Γ}.
  \end{itemize}
\end{itemize}

This is the basic sketch of the algorithm for type-checking
pattern-matching definitions described by \cite{norell:thesis}.
However in our case we not only check that pattern-matchings are
well-formed, we also produce witnesses for this compilation in the core
language, following \cite{DBLP:conf/birthday/GoguenMM06}. 
Now that we have compiled the dependent pattern-matching definition to
a simplified splitting tree, we just need to write a translation
function from trees to \Coq terms.

\subsection{A few constructions}
\label{sec:few-constructions}

The dependent pattern-matching notation acts as a high-level interface 
to a unification procedure on the theory of constructors and
uninterpreted functions. Our first building block in the compilation
process is hence a mechanism to produce witnesses for the resolution of
constraints in this theory, and use these to compile \texttt{Split}
nodes. The proof terms will be formed by applications of simplification 
combinators dealing with substitution and proofs of injectivity and
discrimination of constructors, their two main properties. 

The design of this simplifier is based on the ``specialization by
unification'' method developped by McBride
(\cite{DBLP:conf/types/McBride00,mcbride:concon}). Due to lack of space,
we won't enter in the details of the procedure. The problem we are faced
with is to eliminate an object \var{x} of type $\ind{I} \vec{t}$ in a
goal $τ$ potentialy dependending on $x$. We want the elimination to
produce subgoals for the allowed constructors of this family instance.
To do that, we generalize the goal by fresh variables 
$Δ~(\var{x'} :\ind{I}~Δ)$ and a set of equations asserting that
$\var{x'}$ is equal to $\var{x}$, giving us a new goal: \[ Π~Δ~(\var{x'}
: \ind{I}~Δ), \vec{\bar{Δ_i} \simeq \bar{t_i}} "->" \var{x} \simeq \var{x'}
"->" τ \]

Note that the equations relate terms that may be in different types due
to the fresh indices, hence we use heterogeneous equality $\simeq$ to
relate them. We can apply the standard eliminator for \ind{I} on this
goal to get subgoals corresponding to all its constructors, all starting
with a set of equations relating the indices $t$ of the original
instance to the indices of the constructor. We use a recursive tactic to
simplify these goals, whose completeness have been proven in
\cite{DBLP:conf/birthday/GoguenMM06}. The tactic relies on a set of
combinators for simplifying equations in the theory of contructors, most
of which are just rephrasings of the substitution principles for
\people{Leibniz} and heterogeneous equality. The last bit is a
simplifier for equalities between constructors. We need a tactic that
can simplify any equality $\cstr{C} \vec{t} = \cstr{D} \vec{u}$, 
either giving us equalities between $\vec{t}$ and $\vec{u}$ that can be
further simplified or deriving a contradiction if $\cstr{C}$ is
different from $\cstr{D}$. \cite{mcbride:concon} describes a generic method to
derive such an eliminator that we adapted to $\Coq$. We describe this
construction through a type class \class{NoConfusion}:

\input{noconf.coq}

\subsubsection{Dealing with K}
\label{sec:dealing-with-k}

There is one little twist in our simplifier, due to the fact that \Coq does
not support the principle of ``Uniqueness of Identity Proof'', also
refered to as \people{Streicher}'s K axiom \cite{Streicher}. This
principle can be phrased as:

\coqexternalref{http://coq.inria.fr/distrib/trunk/stdlib/Coq.Logic.ProofIrrelevance}{ProofIrrelevanceTheory.EqdepTheory.UIPrefl}{\coqdoclemma{UIP\_refl}}
: \ensuremath{\forall} (\coqdocvar{U} : \coqdockw{Type}) (\coqdocvar{x}
: \coqdocvariable{U}) (\coqdocvar{p} : \coqdocvariable{x} =
\coqdocvariable{x}), \coqdocvariable{p} = \eqrefl

This principle allows us to simplify a goal depending on a proof $p$ of
$\var{x} = \var{x}$ by substituting the sole constructor \eqrefl{} for
$p$. As we are in an external system, we can easily make use of this
axiom to do the simplifications, but this means that some of our
definitions will not be able to reduce to their expected normal forms: 
they are not closed in the empty context anymore. We will tame this
problem by providing the defining equations as rewrite rules
once a function is accepted, making use of the axiom again to prove
these. 

It is notorious that using rewriting instead of the raw system reduction
during proofs is much more robust and lends itself very well to
automation. Hence we only lose the ability to compute with these
definitions inside \Coq itself, for example as part of reflexive
tactics. At least two proposed extensions to \Coq allow to derive this
principle without any axioms: extensions to make dependent
pattern-matching more powerful w.r.t. indices \cite{TYPES09} and 
the addition of proof-irrelevance. Having them would make \Equations
only more useful.
If we use the extraction mechanism of \Coq \cite{Let2008} that produces
terms in a standard functional language like \ML or \Haskell by removing
all the logical parts of terms, this problem simply disappears.

\input{recursion}
%%% Local Variables: 
%%% mode: latex
%%% TeX-PDF-mode: t
%%% TeX-master: "equations"
%%% End: 